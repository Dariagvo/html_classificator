{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7851698,"sourceType":"datasetVersion","datasetId":4604683}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb\n!pip install 'transformers[torch]'\n!pip install datasets ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-15T16:09:16.033407Z","iopub.execute_input":"2024-03-15T16:09:16.034304Z","iopub.status.idle":"2024-03-15T16:09:53.196457Z","shell.execute_reply.started":"2024-03-15T16:09:16.034258Z","shell.execute_reply":"2024-03-15T16:09:53.195346Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.3)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.40.5)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.38.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.27.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nimport torch\nimport pandas as pd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport numpy as np\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, default_data_collator, XLMRobertaForSequenceClassification\n\nfrom torch.utils.data import DataLoader, TensorDataset\n\nfrom tqdm import tqdm\n\nfrom IPython.display import clear_output\nfrom datasets import load_dataset, Dataset\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:09:53.198667Z","iopub.execute_input":"2024-03-15T16:09:53.198994Z","iopub.status.idle":"2024-03-15T16:10:16.030654Z","shell.execute_reply.started":"2024-03-15T16:09:53.198963Z","shell.execute_reply":"2024-03-15T16:10:16.029818Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-03-15 16:10:05.786352: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-15 16:10:05.786444: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-15 16:10:05.949789: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"def calc_metrics(y_true, y_pred):\n    y_true = y_true.cpu()\n    y_pred = y_pred.cpu()\n    return accuracy_score(y_true, y_pred), precision_score(y_true, y_pred, zero_division=0), recall_score(y_true, y_pred, zero_division=0), f1_score(y_true, y_pred, zero_division=0)\n\n@torch.no_grad()\ndef test(model, loader, device, tqdm_desc):\n    loss_log = []\n    acc_log = []\n    prec_log = []\n    rec_log = []\n    f1_log = []\n    model.eval()\n    loss_func = nn.CrossEntropyLoss()\n\n    for input_ids, attention_mask, labels in loader:\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n\n        out = model(input_ids, attention_mask=attention_mask)\n        loss = loss_func(out.logits, labels)\n\n        loss_log.append(loss.item())\n\n        pred = torch.argmax(out.logits, dim=1)\n        res = calc_metrics(labels, pred)\n        acc_log.append(res[0])\n        prec_log.append(res[1])\n        rec_log.append(res[2])\n        f1_log.append(res[3])\n\n    return loss_log, acc_log, prec_log, rec_log, f1_log\n\n\ndef train(model, optimizer, n_epochs, train_loader, val_loader, batch_size, scheduler=None):\n    train_loss = []\n    train_acc = []\n    train_prec = []\n    train_rec = []\n    train_f1 = []\n    \n    run = wandb.init(project='html classificator', reinit=True)\n    wandb.watch(model, nn.CrossEntropyLoss(), log=\"all\", log_freq=100)\n    model.train()\n\n    batch = 0\n    loss_func = nn.CrossEntropyLoss()\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    for epoch in range(n_epochs):\n        for input_ids, attention_mask, labels in tqdm(train_loader, desc=f'Training {epoch}/{n_epochs}'):\n            batch += 1\n            \n            input_ids = input_ids.to(device)\n            attention_mask = attention_mask.to(device)\n            labels = labels.to(device)\n\n            optimizer.zero_grad()\n            out = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = loss_func(out.logits, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss.append(loss.item())\n\n            pred = torch.argmax(out.logits, dim=1)\n            res = calc_metrics(labels, pred)\n            train_acc.append(res[0])\n            train_prec.append(res[1])\n            train_rec.append(res[2])\n            train_f1.append(res[3])\n            \n            if batch == 500:\n                batch = 0\n                \n                val_loss, val_acc, val_prec, val_rec, val_f1 = test(model, val_loader, device, tqdm_desc='Validating')\n                model.train()\n                \n                wandb.log({\"train\": {\"acc\": np.mean(train_acc), \"pre\": np.mean(train_prec), \"rec\": np.mean(train_rec), \"f1\": np.mean(train_f1), \"loss\": np.mean(train_loss)}, \n                           \"val\": {\"acc\": np.mean(val_acc), \"pre\": np.mean(val_prec), \"rec\": np.mean(val_rec), \"f1\": np.mean(val_f1), \"loss\": np.mean(val_loss)}})\n                \n                # clear_output()\n                print(f\"Next 100 batches:\")\n                print(f\" train loss: {np.mean(train_loss)}, train acc: {np.mean(train_acc)}\")\n                print(f\" val loss: {np.mean(val_loss)}, val acc: {np.mean(val_acc)}\\n\")\n                train_loss = []\n                train_acc = []\n                train_prec = []\n                train_rec = []\n                train_f1 = []\n\n        if scheduler is not None:\n            scheduler.step()\n            \n    # последние батчи\n    val_loss, val_acc, val_prec, val_rec, val_f1 = test(model, val_loader, device, tqdm_desc='Validating')\n                \n    wandb.log({\"train\": {\"acc\": np.mean(train_acc), \"pre\": np.mean(train_prec), \"rec\": np.mean(train_rec), \"f1\": np.mean(train_f1), \"loss\": np.mean(train_loss)}, \n               \"val\": {\"acc\": np.mean(val_acc), \"pre\": np.mean(val_prec), \"rec\": np.mean(val_rec), \"f1\": np.mean(val_f1), \"loss\": np.mean(val_loss)}})\n    print(f\"Last batches:\")\n    print(f\" train loss: {np.mean(train_loss)}, train acc: {np.mean(train_acc)}\")\n    print(f\" val loss: {np.mean(val_loss)}, val acc: {np.mean(val_acc)}\\n\")\n\n    wandb.unwatch()\n    run.finish()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:10:16.031840Z","iopub.execute_input":"2024-03-15T16:10:16.032455Z","iopub.status.idle":"2024-03-15T16:10:16.055824Z","shell.execute_reply.started":"2024-03-15T16:10:16.032427Z","shell.execute_reply":"2024-03-15T16:10:16.054891Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:10:29.285697Z","iopub.execute_input":"2024-03-15T16:10:29.286717Z","iopub.status.idle":"2024-03-15T16:10:29.339975Z","shell.execute_reply.started":"2024-03-15T16:10:29.286660Z","shell.execute_reply":"2024-03-15T16:10:29.338981Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load model directly\n\ntokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\nmodel = XLMRobertaForSequenceClassification.from_pretrained(\"FacebookAI/xlm-roberta-base\").to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:10:31.434276Z","iopub.execute_input":"2024-03-15T16:10:31.434670Z","iopub.status.idle":"2024-03-15T16:10:35.712791Z","shell.execute_reply.started":"2024-03-15T16:10:31.434638Z","shell.execute_reply":"2024-03-15T16:10:35.711922Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"table_path = \"/kaggle/input/site-bin-class/pars_data.csv\"\ndata = pd.read_csv(table_path, on_bad_lines='skip', sep=';', lineterminator='\\n')\ndata.dropna(axis=0, how='any', inplace=True)\ndata.text = data.text.astype(str)\n\ndataset = Dataset.from_pandas(data)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:10:35.714548Z","iopub.execute_input":"2024-03-15T16:10:35.715103Z","iopub.status.idle":"2024-03-15T16:10:50.276421Z","shell.execute_reply.started":"2024-03-15T16:10:35.715067Z","shell.execute_reply":"2024-03-15T16:10:50.275380Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T13:22:18.124032Z","iopub.execute_input":"2024-03-15T13:22:18.124357Z","iopub.status.idle":"2024-03-15T13:22:18.140126Z","shell.execute_reply.started":"2024-03-15T13:22:18.124331Z","shell.execute_reply":"2024-03-15T13:22:18.139150Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                text  target\n0  индивидуальные групповые занятия будни выходны...       1\n1  royal life федеральное театральное агентство «...       0\n2  автоматизированная система uontravel войти заб...       0\n3  уходовая домашняя косметика для души тела зада...       0\n4  новости обучение трейдингу нуля обучение трейд...       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>индивидуальные групповые занятия будни выходны...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>royal life федеральное театральное агентство «...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>автоматизированная система uontravel войти заб...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>уходовая домашняя косметика для души тела зада...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>новости обучение трейдингу нуля обучение трейд...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print('общий размер датасета', data.shape[0])\nprint('количество элементов не из образования', data[data['target'] == 0]['text'].count())\nprint('количество элементов из образования', data[data['target'] == 1]['text'].count())\nprint('максимальный размер строки в датасете', max(len(i) for i in data['text']))","metadata":{"execution":{"iopub.status.busy":"2024-03-15T13:22:18.141224Z","iopub.execute_input":"2024-03-15T13:22:18.141517Z","iopub.status.idle":"2024-03-15T13:22:18.170896Z","shell.execute_reply.started":"2024-03-15T13:22:18.141492Z","shell.execute_reply":"2024-03-15T13:22:18.170048Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"общий размер датасета 47621\nколичество элементов не из образования 34656\nколичество элементов из образования 12965\nмаксимальный размер строки в датасете 1339641\n","output_type":"stream"}]},{"cell_type":"code","source":"TEST_SIZE = 0.3\nSPLIT_RANDOM_SEED = 42\nMAX_LENGTH = 1000000\n\ndef encode(examples):\n    result = tokenizer(examples[\"text\"], truncation=True, max_length=512, padding=\"max_length\")\n    return result\n\ntokenized_datasets = dataset.map(encode, batched=True, remove_columns=\"text\")","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:10:50.278150Z","iopub.execute_input":"2024-03-15T16:10:50.278438Z","iopub.status.idle":"2024-03-15T16:13:05.836718Z","shell.execute_reply.started":"2024-03-15T16:10:50.278413Z","shell.execute_reply":"2024-03-15T16:13:05.835931Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d44a858b1dc4a81817b350ecb2d697b"}},"metadata":{}}]},{"cell_type":"code","source":"input_ids_train, input_ids_v, attention_mask_train, attention_mask_v, label_train, label_v = train_test_split(torch.tensor(tokenized_datasets['input_ids']), \n                                                                                                  torch.tensor(tokenized_datasets['attention_mask']), \n                                                                                                  torch.tensor(tokenized_datasets['target']), \n                                                                                                  random_state=SPLIT_RANDOM_SEED, test_size=TEST_SIZE, shuffle=True)\n\ninput_ids_val, input_ids_test, attention_mask_val, attention_mask_test, label_val, label_test = train_test_split(input_ids_v, attention_mask_v, label_v, \n                                                                                                  random_state=SPLIT_RANDOM_SEED, test_size=0.33, shuffle=True)\n\ntrain_dataset = TensorDataset(input_ids_train, attention_mask_train, label_train)\nval_dataset = TensorDataset(input_ids_val, attention_mask_val, label_val)\ntest_dataset = TensorDataset(input_ids_test, attention_mask_test, label_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:13:05.837904Z","iopub.execute_input":"2024-03-15T16:13:05.838203Z","iopub.status.idle":"2024-03-15T16:13:53.087273Z","shell.execute_reply.started":"2024-03-15T16:13:05.838178Z","shell.execute_reply":"2024-03-15T16:13:53.086119Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:13:53.089387Z","iopub.execute_input":"2024-03-15T16:13:53.089716Z","iopub.status.idle":"2024-03-15T16:13:53.094413Z","shell.execute_reply.started":"2024-03-15T16:13:53.089689Z","shell.execute_reply":"2024-03-15T16:13:53.093749Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"wandb.login(key=\"eba16103be2afd0b5c96243771d60f5d7e562f68\")","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:13:53.095188Z","iopub.execute_input":"2024-03-15T16:13:53.095451Z","iopub.status.idle":"2024-03-15T16:13:55.376095Z","shell.execute_reply.started":"2024-03-15T16:13:53.095428Z","shell.execute_reply":"2024-03-15T16:13:55.375246Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# показания модели imdb (преобученная)\n# model = model.to(device)\nval_loss, val_acc, val_prec, val_rec, val_f1 = test(model, val_loader, device, tqdm_desc='Test')\nprint(f'Без обучения на датасете (чисто модель с параметрами) loss = {np.mean(val_loss)}, accuracy = {np.mean(val_acc)}, precision = {np.mean(val_prec)}, recall = {np.mean(val_rec)}, f1_score = {np.mean(val_f1)}')","metadata":{"execution":{"iopub.status.busy":"2024-03-15T15:47:39.273070Z","iopub.execute_input":"2024-03-15T15:47:39.273771Z","iopub.status.idle":"2024-03-15T15:52:46.829559Z","shell.execute_reply.started":"2024-03-15T15:47:39.273739Z","shell.execute_reply":"2024-03-15T15:52:46.828544Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Test: 100%|██████████| 599/599 [05:07<00:00,  1.95it/s]","output_type":"stream"},{"name":"stdout","text":"Без обучения на датасете (чисто модель с параметрами) loss = 0.8441950186266127, accuracy = 0.27013772954924875, precision = 0.27013772954924875, recall = 0.991652754590985, f1_score = 0.4131570013260478\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T15:58:57.468365Z","iopub.execute_input":"2024-03-15T15:58:57.468713Z","iopub.status.idle":"2024-03-15T15:58:57.785577Z","shell.execute_reply.started":"2024-03-15T15:58:57.468683Z","shell.execute_reply":"2024-03-15T15:58:57.784561Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=2e-5, weight_decay=0.01)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=3, eta_min=3e-10)\ntrain(model, optimizer, 3, train_loader, val_loader, batch_size, scheduler)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T16:13:55.377223Z","iopub.execute_input":"2024-03-15T16:13:55.377792Z","iopub.status.idle":"2024-03-15T20:23:06.139862Z","shell.execute_reply.started":"2024-03-15T16:13:55.377762Z","shell.execute_reply":"2024-03-15T20:23:06.139048Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrodion-chernomordin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240315_161355-3pdqqtr8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/3pdqqtr8' target=\"_blank\">jumping-sun-34</a></strong> to <a href='https://wandb.ai/rodion-chernomordin/html%20classificator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rodion-chernomordin/html%20classificator' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/3pdqqtr8' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/3pdqqtr8</a>"},"metadata":{}},{"name":"stderr","text":"Training 0/3:  24%|██▍       | 500/2084 [19:33<47:37:06, 108.22s/it]","output_type":"stream"},{"name":"stdout","text":"Next 100 batches:\n train loss: 0.3438436353430152, train acc: 0.84425\n val loss: 0.25169663431623546, val acc: 0.8907554257095158\n\n","output_type":"stream"},{"name":"stderr","text":"Training 0/3:  48%|████▊     | 1000/2084 [39:11<32:32:22, 108.07s/it]","output_type":"stream"},{"name":"stdout","text":"Next 100 batches:\n train loss: 0.2522452085465193, train acc: 0.8975\n val loss: 0.25980170067082564, val acc: 0.8956594323873122\n\n","output_type":"stream"},{"name":"stderr","text":"Training 0/3:  72%|███████▏  | 1500/2084 [58:50<17:32:11, 108.10s/it]","output_type":"stream"},{"name":"stdout","text":"Next 100 batches:\n train loss: 0.2665684026386589, train acc: 0.884\n val loss: 0.24996682507093243, val acc: 0.8904424040066778\n\n","output_type":"stream"},{"name":"stderr","text":"Training 0/3:  96%|█████████▌| 2000/2084 [1:18:28<2:31:26, 108.17s/it]","output_type":"stream"},{"name":"stdout","text":"Next 100 batches:\n train loss: 0.2653320294730365, train acc: 0.88825\n val loss: 0.43475175078317696, val acc: 0.8143781302170284\n\n","output_type":"stream"},{"name":"stderr","text":"Training 0/3: 100%|██████████| 2084/2084 [1:20:46<00:00,  2.33s/it]   \nTraining 1/3:  20%|█▉        | 416/2084 [17:19<50:08:09, 108.21s/it]","output_type":"stream"},{"name":"stdout","text":"Next 100 batches:\n train loss: 0.25335297762602565, train acc: 0.890375\n val loss: 0.24690760237449322, val acc: 0.899728714524207\n\n","output_type":"stream"},{"name":"stderr","text":"Training 1/3:  44%|████▍     | 916/2084 [36:58<35:04:58, 108.13s/it]","output_type":"stream"},{"name":"stdout","text":"Next 100 batches:\n train loss: 0.25718214244768023, train acc: 0.892125\n val loss: 0.23911151059052732, val acc: 0.898059265442404\n\n","output_type":"stream"},{"name":"stderr","text":"Training 1/3:  68%|██████▊   | 1416/2084 [56:39<20:10:49, 108.76s/it]","output_type":"stream"},{"name":"stdout","text":"Next 100 batches:\n train loss: 0.2524174031764269, train acc: 0.8965\n val loss: 0.2548285537509742, val acc: 0.8944073455759599\n\n","output_type":"stream"},{"name":"stderr","text":"Training 1/3:  92%|█████████▏| 1916/2084 [1:16:19<5:03:03, 108.24s/it]","output_type":"stream"},{"name":"stdout","text":"Next 100 batches:\n train loss: 0.2632292756102979, train acc: 0.884625\n val loss: 0.2556516764940498, val acc: 0.8961811352253757\n\n","output_type":"stream"},{"name":"stderr","text":"Training 1/3: 100%|██████████| 2084/2084 [1:20:56<00:00,  2.33s/it]   \nTraining 2/3:  16%|█▌        | 332/2084 [15:00<52:39:04, 108.19s/it]","output_type":"stream"},{"name":"stdout","text":"Next 100 batches:\n train loss: 0.2546376099102199, train acc: 0.8899166666666666\n val loss: 0.23969308298410777, val acc: 0.8973288814691152\n\n","output_type":"stream"},{"name":"stderr","text":"Training 2/3:  40%|███▉      | 832/2084 [34:40<37:38:38, 108.24s/it]","output_type":"stream"},{"name":"stdout","text":"Next 100 batches:\n train loss: 0.24277572084218263, train acc: 0.895625\n val loss: 0.24984589096419949, val acc: 0.9010851419031719\n\n","output_type":"stream"},{"name":"stderr","text":"Training 2/3:  64%|██████▍   | 1332/2084 [54:19<22:37:33, 108.32s/it]","output_type":"stream"},{"name":"stdout","text":"Next 100 batches:\n train loss: 0.24453319256380202, train acc: 0.89575\n val loss: 0.23990811820364308, val acc: 0.8995200333889817\n\n","output_type":"stream"},{"name":"stderr","text":"Training 2/3:  88%|████████▊ | 1832/2084 [1:13:57<7:34:22, 108.18s/it]","output_type":"stream"},{"name":"stdout","text":"Next 100 batches:\n train loss: 0.24176935820281506, train acc: 0.897375\n val loss: 0.2338708041232695, val acc: 0.9017111853088481\n\n","output_type":"stream"},{"name":"stderr","text":"Training 2/3: 100%|██████████| 2084/2084 [1:20:55<00:00,  2.33s/it]   \n","output_type":"stream"},{"name":"stdout","text":"Last batches:\n train loss: 0.24218072983184977, train acc: 0.8946759259259259\n val loss: 0.23673500844241682, val acc: 0.9010851419031719\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">jumping-sun-34</strong> at: <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/3pdqqtr8' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/3pdqqtr8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240315_161355-3pdqqtr8/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"test_loss, test_acc, test_prec, test_rec, test_f1 = test(model, test_loader, device, tqdm_desc='Test')\nprint(f'loss = {np.mean(test_loss)}, accuracy = {np.mean(test_acc)}, precision = {np.mean(test_prec)}, recall = {np.mean(test_rec)}, f1_score = {np.mean(test_f1)}')","metadata":{"execution":{"iopub.status.busy":"2024-03-15T20:23:06.141830Z","iopub.execute_input":"2024-03-15T20:23:06.142114Z","iopub.status.idle":"2024-03-15T20:25:41.736666Z","shell.execute_reply.started":"2024-03-15T20:23:06.142087Z","shell.execute_reply":"2024-03-15T20:25:41.735530Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"loss = 0.22772546339211827, accuracy = 0.9044491525423729, precision = 0.8426836158192089, recall = 0.7995466774280334, f1_score = 0.798695709903665\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}