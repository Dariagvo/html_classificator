{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb\n!pip install 'transformers[torch]' \n!pip install datasets \n!pip install evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-09T09:00:23.110575Z","iopub.execute_input":"2024-02-09T09:00:23.111422Z","iopub.status.idle":"2024-02-09T09:01:16.033792Z","shell.execute_reply.started":"2024-02-09T09:00:23.111387Z","shell.execute_reply":"2024-02-09T09:01:16.032610Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.32)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.39.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.1.2)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.36.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.20.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch!=1.12.0,>=1.10 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.0.0)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.25.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.12.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting evaluate\n  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.24.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.12.2)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.20.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m873.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AlbertForSequenceClassification, AlbertConfig, Trainer, TrainingArguments, AutoModelForSequenceClassification\nfrom transformers import default_data_collator\n\nimport evaluate\n\nfrom torch.utils.data import DataLoader, TensorDataset\n\nfrom tqdm import tqdm\n\nfrom IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:01:16.035858Z","iopub.execute_input":"2024-02-09T09:01:16.036211Z","iopub.status.idle":"2024-02-09T09:01:36.472907Z","shell.execute_reply.started":"2024-02-09T09:01:16.036168Z","shell.execute_reply":"2024-02-09T09:01:36.472066Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"def encode(examples):\n    result = tokenizer(examples[\"text\"], truncation=True, max_length=512, padding=\"max_length\")\n    return result\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n\n@torch.no_grad()\ndef test(model, loader, device, tqdm_desc):\n    loss_log = []\n    acc_log = []\n    model.eval()\n    loss_func = nn.CrossEntropyLoss()\n\n    for input_ids, attention_mask, labels in tqdm(loader, desc=tqdm_desc):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n\n        out = model(input_ids, attention_mask=attention_mask)\n        loss = loss_func(out.logits, labels)\n\n        loss_log.append(loss.item())\n\n        pred = torch.argmax(out.logits, dim=1)\n        acc_log.append((pred == labels).detach().cpu().numpy().sum() / len(pred))\n\n    return loss_log, acc_log\n\n\ndef train_epoch(model, optimizer, train_loader, device, tqdm_desc):\n    loss_log = []\n    acc_log = []\n    model.train()\n    loss_func = nn.CrossEntropyLoss()\n\n    for input_ids, attention_mask, labels in tqdm(train_loader, desc=tqdm_desc):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        out = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = loss_func(out.logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        loss_log.append(loss.item())\n\n        pred = torch.argmax(out.logits, dim=1)\n        acc_log.append((pred == labels).detach().cpu().numpy().sum() / len(pred))\n\n    return loss_log, acc_log\n\n\ndef train(model, optimizer, n_epochs, train_loader, val_loader, batch_size, scheduler=None):\n    train_loss_log, train_acc_log, val_loss_log, val_acc_log = [], [], [], []\n    train_len_epoch_loss = []\n    train_len_epoch_acc = []\n    \n    run = wandb.init(project='html classificator', reinit=True)\n    \n    wandb.watch(model, nn.CrossEntropyLoss(), log=\"all\", log_freq=1)\n\n    count = len(train_loader) // batch_size\n    for epoch in range(n_epochs):\n        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n        train_loss, train_acc = train_epoch(model, optimizer, train_loader, device, tqdm_desc=f'Training {epoch}/{n_epochs}')\n        val_loss, val_acc = test(model, val_loader, device, tqdm_desc=f'Validating {epoch}/{n_epochs}')\n\n        train_loss_log.extend(train_loss)\n        train_acc_log.extend(train_acc)\n\n        val_loss_log.extend(val_loss)\n        val_acc_log.extend(val_acc)\n\n        # wandb\n        wandb.log({\"Accuracy\": wandb.plot.line_series(\n                xs=list(range((epoch + 1) * count)),\n                ys=[train_acc_log, val_acc_log],\n                keys=[\"train\", \"val\"],\n                title=\"Accuracy\",\n                xname=\"iter\")})\n        \n        wandb.log({\"Loss\": wandb.plot.line_series(\n                xs=list(range((epoch + 1) * count)),\n                ys=[train_loss_log, val_loss_log],\n                keys=[\"train\", \"val\"],\n                title=\"Loss\",\n                xname=\"iter\")})\n\n#         clear_output()\n        print(f\"Epoch {epoch + 1}\")\n        print(f\" train loss: {np.mean(train_loss)}, train acc: {np.mean(train_acc)}\")\n        print(f\" val loss: {np.mean(val_loss)}, val acc: {np.mean(val_acc)}\\n\")\n\n        if scheduler is not None:\n            scheduler.step()\n\n    run.finish()\n    return train_loss_log, train_acc_log, val_loss_log, val_acc_log","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:01:36.474062Z","iopub.execute_input":"2024-02-09T09:01:36.474652Z","iopub.status.idle":"2024-02-09T09:01:36.497017Z","shell.execute_reply.started":"2024-02-09T09:01:36.474624Z","shell.execute_reply":"2024-02-09T09:01:36.496089Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:01:36.498931Z","iopub.execute_input":"2024-02-09T09:01:36.499210Z","iopub.status.idle":"2024-02-09T09:01:36.593114Z","shell.execute_reply.started":"2024-02-09T09:01:36.499173Z","shell.execute_reply":"2024-02-09T09:01:36.591952Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(\"XSY/albert-base-v2-imdb-calssification\")\n# model = AlbertForSequenceClassification(AlbertConfig()).cuda()\n\nmetric = evaluate.load(\"accuracy\")\n\ntokenizer = AutoTokenizer.from_pretrained(\"XSY/albert-base-v2-imdb-calssification\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"XSY/albert-base-v2-imdb-calssification\").to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:01:36.594333Z","iopub.execute_input":"2024-02-09T09:01:36.594662Z","iopub.status.idle":"2024-02-09T09:01:39.434068Z","shell.execute_reply.started":"2024-02-09T09:01:36.594635Z","shell.execute_reply":"2024-02-09T09:01:39.433255Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50d6357d4805461391fbc841ab83252c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2260a0060514a6290d9919e8bb0be74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e42fe1a670a84892b077636bfeb767ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/245 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdd934551f50451ba3551602d6f20191"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/889 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56a62653d85e43e3b54c36b0eb6dd5c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/46.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92173ad7aa004b33b90c79506d84b449"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = load_dataset(\"imdb\")\ntokenized_datasets = dataset.map(encode, batched=True, remove_columns=\"text\")\n\ntrain_dataset = TensorDataset(torch.tensor(tokenized_datasets['train']['input_ids']), torch.tensor(tokenized_datasets['train']['attention_mask']), torch.tensor(tokenized_datasets['train']['label']))\ntest_dataset = TensorDataset(torch.tensor(tokenized_datasets['test']['input_ids']), torch.tensor(tokenized_datasets['test']['attention_mask']), torch.tensor(tokenized_datasets['test']['label']))\n\nbatch_size = 16\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:01:39.435496Z","iopub.execute_input":"2024-02-09T09:01:39.435961Z","iopub.status.idle":"2024-02-09T09:04:33.039679Z","shell.execute_reply.started":"2024-02-09T09:01:39.435925Z","shell.execute_reply":"2024-02-09T09:04:33.038736Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4aba9064bc154ac5869ad9ed90af975e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c3f40a35d3d427bbf435b565398e123"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abda821968f046d5b4cf13e64ed5e3ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b7874a954c04017b7c7fff6401ddfc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d094110f9df4b9fb6d55016ec27321c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4c1c1b464ab4411b9e51bdd0a70b457"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b83fa93f61f54c2e9259b53c2da1501c"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2024-02-07T14:30:05.652060Z","iopub.execute_input":"2024-02-07T14:30:05.652472Z","iopub.status.idle":"2024-02-07T14:30:05.660255Z","shell.execute_reply.started":"2024-02-07T14:30:05.652441Z","shell.execute_reply":"2024-02-07T14:30:05.659289Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 25000\n    })\n    unsupervised: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 50000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"wandb.login(key=\"eba16103be2afd0b5c96243771d60f5d7e562f68\")","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:04:33.040934Z","iopub.execute_input":"2024-02-09T09:04:33.041289Z","iopub.status.idle":"2024-02-09T09:04:35.059930Z","shell.execute_reply.started":"2024-02-09T09:04:33.041260Z","shell.execute_reply":"2024-02-09T09:04:35.059024Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# model = model.to(device)\nval_loss, val_acc = test(model, val_loader, device, tqdm_desc='Test')\nprint(f'Без обучения на датасете (чисто модель с параметрами) loss = {np.mean(val_loss)}, accuracy = {np.mean(val_acc)}')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T11:16:01.663487Z","iopub.execute_input":"2024-02-08T11:16:01.664218Z","iopub.status.idle":"2024-02-08T11:31:45.287849Z","shell.execute_reply.started":"2024-02-08T11:16:01.664183Z","shell.execute_reply":"2024-02-08T11:31:45.286797Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Test: 100%|██████████| 1563/1563 [15:43<00:00,  1.66it/s]","output_type":"stream"},{"name":"stdout","text":"Без обучения на датасете (чисто модель с параметрами) loss = 0.1985105358434201, accuracy = 0.9360204734484965\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# model = model.to(device)\noptimizer = optim.Adam(model.parameters(), lr=2e-5, weight_decay=0.01)\ntrain_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer, 3, train_loader, val_loader, batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T14:11:41.294072Z","iopub.execute_input":"2024-02-08T14:11:41.295091Z","iopub.status.idle":"2024-02-08T17:22:51.092928Z","shell.execute_reply.started":"2024-02-08T14:11:41.295056Z","shell.execute_reply":"2024-02-08T17:22:51.092022Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:1j434940) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">grateful-surf-16</strong> at: <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/1j434940' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/1j434940</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240208_130549-1j434940/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:1j434940). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240208_141141-hkbzi7x5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/hkbzi7x5' target=\"_blank\">wandering-frog-17</a></strong> to <a href='https://wandb.ai/rodion-chernomordin/html%20classificator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rodion-chernomordin/html%20classificator' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/hkbzi7x5' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/hkbzi7x5</a>"},"metadata":{}},{"name":"stderr","text":"Training 0/3: 100%|██████████| 1563/1563 [44:08<00:00,  1.69s/it]\nValidating 0/3: 100%|██████████| 1563/1563 [19:23<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1\n train loss: 0.16785732328043257, train acc: 0.9389795265515035\n val loss: 0.1752058006864773, val acc: 0.9335812539987204\n\n","output_type":"stream"},{"name":"stderr","text":"Training 1/3: 100%|██████████| 1563/1563 [44:05<00:00,  1.69s/it]\nValidating 1/3: 100%|██████████| 1563/1563 [19:23<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2\n train loss: 0.13657005596608018, train acc: 0.9504958413307741\n val loss: 0.21571108164794275, val acc: 0.9181062060140754\n\n","output_type":"stream"},{"name":"stderr","text":"Training 2/3: 100%|██████████| 1563/1563 [44:05<00:00,  1.69s/it]\nValidating 2/3: 100%|██████████| 1563/1563 [19:22<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3\n train loss: 0.11670218710862076, train acc: 0.9582933461292387\n val loss: 0.2059667423575752, val acc: 0.9221049264235445\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.110 MB of 0.129 MB uploaded\\r'), FloatProgress(value=0.8477836324109216, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wandering-frog-17</strong> at: <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/hkbzi7x5' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/hkbzi7x5</a><br/>Synced 6 W&B file(s), 6 media file(s), 6 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240208_141141-hkbzi7x5/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T14:11:30.355420Z","iopub.execute_input":"2024-02-08T14:11:30.355758Z","iopub.status.idle":"2024-02-08T14:11:30.672543Z","shell.execute_reply.started":"2024-02-08T14:11:30.355732Z","shell.execute_reply":"2024-02-08T14:11:30.671462Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=2e-5, weight_decay=0.01)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=3, eta_min=3e-10)\ntrain_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer, 3, train_loader, val_loader, batch_size, scheduler)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T09:40:56.861699Z","iopub.execute_input":"2024-02-09T09:40:56.862592Z","iopub.status.idle":"2024-02-09T13:10:42.934488Z","shell.execute_reply.started":"2024-02-09T09:40:56.862556Z","shell.execute_reply":"2024-02-09T13:10:42.933604Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrodion-chernomordin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240209_094056-6bs2jjcm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/6bs2jjcm' target=\"_blank\">dark-cloud-18</a></strong> to <a href='https://wandb.ai/rodion-chernomordin/html%20classificator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rodion-chernomordin/html%20classificator' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/6bs2jjcm' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/6bs2jjcm</a>"},"metadata":{}},{"name":"stderr","text":"Training 0/3: 100%|██████████| 1563/1563 [47:48<00:00,  1.84s/it]\nValidating 0/3: 100%|██████████| 1563/1563 [22:21<00:00,  1.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1\n train loss: 0.1664096171725172, train acc: 0.9387396033269354\n val loss: 0.18684211791530536, val acc: 0.9258237364043506\n\n","output_type":"stream"},{"name":"stderr","text":"Training 1/3: 100%|██████████| 1563/1563 [47:47<00:00,  1.83s/it]\nValidating 1/3: 100%|██████████| 1563/1563 [20:55<00:00,  1.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2\n train loss: 0.11898303203617228, train acc: 0.9587731925783749\n val loss: 0.215617141500026, val acc: 0.9220649392194498\n\n","output_type":"stream"},{"name":"stderr","text":"Training 2/3: 100%|██████████| 1563/1563 [48:09<00:00,  1.85s/it]\nValidating 2/3: 100%|██████████| 1563/1563 [22:04<00:00,  1.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3\n train loss: 0.05993715412082044, train acc: 0.9812859884836852\n val loss: 0.21360904601218164, val acc: 0.93170185540627\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.129 MB of 0.129 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dark-cloud-18</strong> at: <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/6bs2jjcm' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/6bs2jjcm</a><br/>Synced 6 W&B file(s), 6 media file(s), 6 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240209_094056-6bs2jjcm/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"model_name = \"albert\"\nargs = TrainingArguments(\n    f\"{model_name}-finetuned-squad\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n)\n\nwandb.login(key=\"eba16103be2afd0b5c96243771d60f5d7e562f68\")\n\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-27T10:01:27.450846Z","iopub.execute_input":"2024-01-27T10:01:27.451703Z","iopub.status.idle":"2024-01-27T11:31:23.452718Z","shell.execute_reply.started":"2024-01-27T10:01:27.451667Z","shell.execute_reply":"2024-01-27T11:31:23.451542Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2346/2346 1:29:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.158600</td>\n      <td>0.177705</td>\n      <td>0.936000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.087800</td>\n      <td>0.211011</td>\n      <td>0.937120</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.053800</td>\n      <td>0.286730</td>\n      <td>0.939360</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2346, training_loss=0.09775648580487732, metrics={'train_runtime': 5395.4903, 'train_samples_per_second': 13.9, 'train_steps_per_second': 0.435, 'total_flos': 1792357632000000.0, 'train_loss': 0.09775648580487732, 'epoch': 3.0})"},"metadata":{}}]}]}