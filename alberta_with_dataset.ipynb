{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7212408,"sourceType":"datasetVersion","datasetId":4173433}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-16T22:52:15.741797Z","iopub.execute_input":"2024-03-16T22:52:15.742547Z","iopub.status.idle":"2024-03-16T22:52:28.001126Z","shell.execute_reply.started":"2024-03-16T22:52:15.742510Z","shell.execute_reply":"2024-03-16T22:52:28.000167Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.3)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.40.5)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AlbertTokenizer, AlbertForSequenceClassification, AdamW\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom tqdm.notebook import tqdm\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2024-03-16T22:52:28.002612Z","iopub.execute_input":"2024-03-16T22:52:28.003104Z","iopub.status.idle":"2024-03-16T22:52:28.011231Z","shell.execute_reply.started":"2024-03-16T22:52:28.003064Z","shell.execute_reply":"2024-03-16T22:52:28.010567Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import time\n\n# Создаем список для итерации\nitems = list(range(10))\n\n# Используем tqdm для создания прогресс-бара\nfor item in tqdm(items, desc='Прогресс'):\n    # Имитируем задержку для наглядности\n    time.sleep(0.5)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T22:52:28.012270Z","iopub.execute_input":"2024-03-16T22:52:28.012494Z","iopub.status.idle":"2024-03-16T22:52:33.060890Z","shell.execute_reply.started":"2024-03-16T22:52:28.012473Z","shell.execute_reply":"2024-03-16T22:52:33.059983Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Прогресс:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0699ec208e6c455fb24845af1c51ae24"}},"metadata":{}}]},{"cell_type":"code","source":"wandb.login()\nwandb.init(project=\"base001\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T22:52:35.025169Z","iopub.execute_input":"2024-03-16T22:52:35.025969Z","iopub.status.idle":"2024-03-16T22:53:16.906102Z","shell.execute_reply.started":"2024-03-16T22:52:35.025927Z","shell.execute_reply":"2024-03-16T22:53:16.905189Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myaeooa\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240316_225246-hxhp5uif</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/yaeooa/base001/runs/hxhp5uif' target=\"_blank\">mild-shape-7</a></strong> to <a href='https://wandb.ai/yaeooa/base001' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/yaeooa/base001' target=\"_blank\">https://wandb.ai/yaeooa/base001</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/yaeooa/base001/runs/hxhp5uif' target=\"_blank\">https://wandb.ai/yaeooa/base001/runs/hxhp5uif</a>"},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/yaeooa/base001/runs/hxhp5uif?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7ea885f3e830>"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/zxcvbn/pars_data.csv', delimiter=';')\ndata.columns = ['text', 'target']\ndata.dropna(inplace=True)\ndata = data.sample(n=15000, random_state=42)\n\nclass_counts = data['target'].value_counts()\nprint(\"Количество примеров в каждом классе:\")\nprint(class_counts)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T22:53:19.953977Z","iopub.execute_input":"2024-03-16T22:53:19.954400Z","iopub.status.idle":"2024-03-16T22:53:33.986186Z","shell.execute_reply.started":"2024-03-16T22:53:19.954366Z","shell.execute_reply":"2024-03-16T22:53:33.985170Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Количество примеров в каждом классе:\ntarget\n0    10923\n1     4077\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_text(texts, tokenizer, max_length):\n    input_ids = []\n    attention_masks = []\n\n    for text in tqdm(texts, desc=\"Tokenization Progress\"):\n        encoded_text = tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=max_length,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        input_ids.append(encoded_text['input_ids'])\n        attention_masks.append(encoded_text['attention_mask'])\n\n    input_ids = torch.cat(input_ids, dim=0)\n    attention_masks = torch.cat(attention_masks, dim=0)\n\n    return input_ids, attention_masks\n\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(data['text'], data['target'], test_size=0.2, random_state=42)\nval_texts, test_texts, val_labels, test_labels = train_test_split(test_texts, test_labels, test_size=0.5, random_state=42)\n\ntokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n\nmax_length = 512\n\ntrain_input_ids, train_attention_masks = tokenize_text(train_texts, tokenizer, max_length)\nval_input_ids, val_attention_masks = tokenize_text(val_texts, tokenizer, max_length)\ntest_input_ids, test_attention_masks = tokenize_text(test_texts, tokenizer, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T22:53:39.547847Z","iopub.execute_input":"2024-03-16T22:53:39.548587Z","iopub.status.idle":"2024-03-16T22:58:52.302485Z","shell.execute_reply.started":"2024-03-16T22:53:39.548551Z","shell.execute_reply":"2024-03-16T22:58:52.301508Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ec1dc5474b943a1a6d6dbc3a85042fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dce2ad123425451b939471f5e833df64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3027201b7c742889e86c7d762312250"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"054272e0dd3844e19cbf1d564bac79df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenization Progress:   0%|          | 0/12000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83fdfd4201854398a6f8dfc199322ce4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenization Progress:   0%|          | 0/1500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbe95d6cc9064ec1b1dc2c7c2ccb9879"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenization Progress:   0%|          | 0/1500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3352a742a0c4003bb5061d01de3fbfa"}},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 16\n\ntrain_dataset = TensorDataset(train_input_ids, train_attention_masks, torch.tensor(train_labels.values))\nval_dataset = TensorDataset(val_input_ids, val_attention_masks, torch.tensor(val_labels.values))\ntest_dataset = TensorDataset(test_input_ids, test_attention_masks, torch.tensor(test_labels.values))\n\ntrain_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\nval_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)\ntest_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T22:59:06.880219Z","iopub.execute_input":"2024-03-16T22:59:06.880579Z","iopub.status.idle":"2024-03-16T22:59:06.901766Z","shell.execute_reply.started":"2024-03-16T22:59:06.880549Z","shell.execute_reply":"2024-03-16T22:59:06.900566Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels=2)\nmodel.cuda()\noptimizer = AdamW(model.parameters(), lr=1e-5)\nepochs = 3\n\nclass_weights = torch.tensor([class_counts[1]/class_counts[0], 1.0], dtype=torch.float).cuda()\nloss_function = torch.nn.CrossEntropyLoss(weight=class_weights)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T22:59:10.723745Z","iopub.execute_input":"2024-03-16T22:59:10.724128Z","iopub.status.idle":"2024-03-16T22:59:11.898151Z","shell.execute_reply.started":"2024-03-16T22:59:10.724095Z","shell.execute_reply":"2024-03-16T22:59:11.896280Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bf0170937fe468fbf127aef4e4530ce"}},"metadata":{}},{"name":"stderr","text":"Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(epochs):\n    model.train()\n    train_losses = []\n\n    for batch in tqdm(train_dataloader, desc=\"Epoch: {}\".format(epoch + 1)):\n        batch = tuple(t.cuda() for t in batch)\n        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n        optimizer.zero_grad()\n        outputs = model(**inputs)\n        loss = loss_function(outputs.logits, inputs['labels'])\n        train_losses.append(loss.item())\n        loss.backward()\n        optimizer.step()\n\n    train_loss = np.mean(train_losses)\n    wandb.log({\"Train Loss\": train_loss})\n\n    model.eval()\n    val_losses = []\n    val_predictions = []\n    val_true_labels = []\n\n    for batch in val_dataloader:\n        batch = tuple(t.cuda() for t in batch)\n        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n        with torch.no_grad():\n            outputs = model(**inputs)\n\n        loss = loss_function(outputs.logits, inputs['labels'])\n        val_losses.append(loss.item())\n        logits = outputs.logits\n        val_predictions.extend(torch.argmax(logits, dim=1).tolist())\n        val_true_labels.extend(inputs['labels'].tolist())\n\n    val_loss = np.mean(val_losses)\n    val_accuracy = accuracy_score(val_true_labels, val_predictions)\n    val_precision = precision_score(val_true_labels, val_predictions)\n    val_recall = recall_score(val_true_labels, val_predictions)\n    val_f1 = f1_score(val_true_labels, val_predictions)\n\n    wandb.log({\"Val Loss\": val_loss,\n               \"Val Accuracy\": val_accuracy,\n               \"Val Precision\": val_precision,\n               \"Val Recall\": val_recall,\n               \"Val F1\": val_f1})\n\n    print(\"Epoch {} - Train Loss: {:.4f}, Val Loss: {:.4f}, Val Accuracy: {:.4f}, Val Precision: {:.4f}, Val Recall: {:.4f}, Val F1: {:.4f}\".format(\n        epoch + 1, train_loss, val_loss, val_accuracy, val_precision, val_recall, val_f1))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T22:59:15.644459Z","iopub.execute_input":"2024-03-16T22:59:15.644856Z","iopub.status.idle":"2024-03-17T00:06:08.820124Z","shell.execute_reply.started":"2024-03-16T22:59:15.644824Z","shell.execute_reply":"2024-03-17T00:06:08.818964Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch: 1:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa8a508003e7411bb94899ad827e193f"}},"metadata":{}},{"name":"stdout","text":"Epoch 1 - Train Loss: 0.6164, Val Loss: 0.5495, Val Accuracy: 0.7493, Val Precision: 0.5305, Val Recall: 0.7220, Val F1: 0.6116\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch: 2:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42f95eee84b14307a91bb776a601e74e"}},"metadata":{}},{"name":"stdout","text":"Epoch 2 - Train Loss: 0.5280, Val Loss: 0.5197, Val Accuracy: 0.7713, Val Precision: 0.5682, Val Recall: 0.6805, Val F1: 0.6193\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch: 3:   0%|          | 0/750 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0268e97dc1d746b3b4c4f90cfdf3d4d8"}},"metadata":{}},{"name":"stdout","text":"Epoch 3 - Train Loss: 0.4615, Val Loss: 0.4889, Val Accuracy: 0.7693, Val Precision: 0.5556, Val Recall: 0.7805, Val F1: 0.6491\n","output_type":"stream"}]},{"cell_type":"code","source":"test_predictions = []\ntest_true_labels = []\n\nfor batch in test_dataloader:\n    batch = tuple(t.cuda() for t in batch)\n    inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n    with torch.no_grad():\n        outputs = model(**inputs)\n\n    logits = outputs.logits\n    test_predictions.extend(torch.argmax(logits, dim=1).tolist())\n    test_true_labels.extend(inputs['labels'].tolist())\n\ntest_accuracy = accuracy_score(test_true_labels, test_predictions)\ntest_precision = precision_score(test_true_labels, test_predictions)\ntest_recall = recall_score(test_true_labels, test_predictions)\ntest_f1 = f1_score(test_true_labels, test_predictions)\n\nprint(\"Test Accuracy: {:.4f}, Test Precision: {:.4f}, Test Recall: {:.4f}, Test F1: {:.4f}\".format(\n    test_accuracy, test_precision, test_recall, test_f1))","metadata":{"execution":{"iopub.status.busy":"2024-03-17T00:07:09.673741Z","iopub.execute_input":"2024-03-17T00:07:09.674014Z","iopub.status.idle":"2024-03-17T00:08:10.516747Z","shell.execute_reply.started":"2024-03-17T00:07:09.673989Z","shell.execute_reply":"2024-03-17T00:08:10.515526Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.7500, Test Precision: 0.5144, Test Recall: 0.7315, Test F1: 0.6040\n","output_type":"stream"}]}]}