{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb\n!pip install 'transformers[torch]' \n!pip install datasets \n!pip install evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-16T17:32:44.175063Z","iopub.execute_input":"2024-02-16T17:32:44.175687Z","iopub.status.idle":"2024-02-16T17:33:35.135232Z","shell.execute_reply.started":"2024-02-16T17:32:44.175655Z","shell.execute_reply":"2024-02-16T17:33:35.134029Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.32)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.39.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.1.2)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.36.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.20.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch!=1.12.0,>=1.10 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.0.0)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.25.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.12.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting evaluate\n  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.24.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.12.2)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.20.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m987.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AlbertForSequenceClassification, AlbertConfig, Trainer, TrainingArguments, AutoModelForSequenceClassification\nfrom transformers import default_data_collator\n\nimport evaluate\n\nfrom torch.utils.data import DataLoader, TensorDataset\n\nfrom tqdm import tqdm\n\nfrom IPython.display import clear_output\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-02-16T17:33:35.137813Z","iopub.execute_input":"2024-02-16T17:33:35.138590Z","iopub.status.idle":"2024-02-16T17:33:37.452139Z","shell.execute_reply.started":"2024-02-16T17:33:35.138551Z","shell.execute_reply":"2024-02-16T17:33:37.451320Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"TEST_SIZE = 0.3\nSPLIT_RANDOM_SEED = 42","metadata":{"execution":{"iopub.status.busy":"2024-02-16T17:33:37.453310Z","iopub.execute_input":"2024-02-16T17:33:37.453604Z","iopub.status.idle":"2024-02-16T17:33:37.457952Z","shell.execute_reply.started":"2024-02-16T17:33:37.453578Z","shell.execute_reply":"2024-02-16T17:33:37.456847Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def encode(examples):\n    result = tokenizer(examples[\"text\"], truncation=True, max_length=512, padding=\"max_length\")\n    return result\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n\n@torch.no_grad()\ndef test(model, loader, device, tqdm_desc):\n    loss_log = []\n    acc_log = []\n    model.eval()\n    loss_func = nn.CrossEntropyLoss()\n\n    for input_ids, attention_mask, labels in tqdm(loader, desc=tqdm_desc):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n\n        out = model(input_ids, attention_mask=attention_mask)\n        loss = loss_func(out.logits, labels)\n\n        loss_log.append(loss.item())\n\n        pred = torch.argmax(out.logits, dim=1)\n        acc_log.append((pred == labels).detach().cpu().numpy().sum() / len(pred))\n\n    return loss_log, acc_log\n\n\ndef train_epoch(model, optimizer, train_loader, device, tqdm_desc):\n    loss_log = []\n    acc_log = []\n    model.train()\n    loss_func = nn.CrossEntropyLoss()\n\n    for input_ids, attention_mask, labels in tqdm(train_loader, desc=tqdm_desc):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        out = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = loss_func(out.logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        loss_log.append(loss.item())\n\n        pred = torch.argmax(out.logits, dim=1)\n        acc_log.append((pred == labels).detach().cpu().numpy().sum() / len(pred))\n\n    return loss_log, acc_log\n\n\ndef train(model, optimizer, n_epochs, train_loader, val_loader, batch_size, scheduler=None):\n    train_loss_log, train_acc_log, val_loss_log, val_acc_log = [], [], [], []\n    train_len_epoch_loss = []\n    train_len_epoch_acc = []\n    \n    run = wandb.init(project='html classificator', reinit=True)\n    \n    wandb.watch(model, nn.CrossEntropyLoss(), log=\"all\", log_freq=1)\n\n    count = len(train_loader) // batch_size\n    for epoch in range(n_epochs):\n        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n        train_loss, train_acc = train_epoch(model, optimizer, train_loader, device, tqdm_desc=f'Training {epoch}/{n_epochs}')\n        val_loss, val_acc = test(model, val_loader, device, tqdm_desc=f'Validating {epoch}/{n_epochs}')\n\n        train_loss_log.extend(train_loss)\n        train_acc_log.extend(train_acc)\n\n        val_loss_log.extend(val_loss)\n        val_acc_log.extend(val_acc)\n\n        # wandb\n        wandb.log({\"Accuracy\": wandb.plot.line_series(\n                xs=list(range((epoch + 1) * count)),\n                ys=[train_acc_log, val_acc_log],\n                keys=[\"train\", \"val\"],\n                title=\"Accuracy\",\n                xname=\"iter\")})\n        \n        wandb.log({\"Loss\": wandb.plot.line_series(\n                xs=list(range((epoch + 1) * count)),\n                ys=[train_loss_log, val_loss_log],\n                keys=[\"train\", \"val\"],\n                title=\"Loss\",\n                xname=\"iter\")})\n\n#         clear_output()\n        print(f\"Epoch {epoch + 1}\")\n        print(f\" train loss: {np.mean(train_loss)}, train acc: {np.mean(train_acc)}\")\n        print(f\" val loss: {np.mean(val_loss)}, val acc: {np.mean(val_acc)}\\n\")\n\n        if scheduler is not None:\n            scheduler.step()\n\n    wandb.unwatch()\n    run.finish()\n    return train_loss_log, train_acc_log, val_loss_log, val_acc_log","metadata":{"execution":{"iopub.status.busy":"2024-02-16T17:33:37.461315Z","iopub.execute_input":"2024-02-16T17:33:37.461991Z","iopub.status.idle":"2024-02-16T17:33:37.490799Z","shell.execute_reply.started":"2024-02-16T17:33:37.461953Z","shell.execute_reply":"2024-02-16T17:33:37.489851Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T17:33:37.491928Z","iopub.execute_input":"2024-02-16T17:33:37.492825Z","iopub.status.idle":"2024-02-16T17:33:37.554485Z","shell.execute_reply.started":"2024-02-16T17:33:37.492791Z","shell.execute_reply":"2024-02-16T17:33:37.553409Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(\"XSY/albert-base-v2-imdb-calssification\")\n# model = AlbertForSequenceClassification(AlbertConfig()).cuda()\n\n# Load model directly\n\n\ntokenizer = AutoTokenizer.from_pretrained(\"albert/albert-base-v2\")\nmodel = AlbertForSequenceClassification.from_pretrained(\"albert/albert-base-v2\").to(device)\n\nmetric = evaluate.load(\"accuracy\")\n\n# tokenizer = AutoTokenizer.from_pretrained(\"XSY/albert-base-v2-imdb-calssification\")\n# model = AutoModelForSequenceClassification.from_pretrained(\"XSY/albert-base-v2-imdb-calssification\").to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T17:33:37.555834Z","iopub.execute_input":"2024-02-16T17:33:37.556200Z","iopub.status.idle":"2024-02-16T17:33:40.403501Z","shell.execute_reply.started":"2024-02-16T17:33:37.556173Z","shell.execute_reply":"2024-02-16T17:33:40.402764Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a74725bf35084627b9feadf9c4e339d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"966a1bb66df04be58c9be74e8e210d5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2158b582c8664e338a7c914ae6c36e24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2669912105e34e9f892f7dbbc20ff401"}},"metadata":{}},{"name":"stderr","text":"Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d204a2795d843119a1c7ca9fc6d89a5"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = load_dataset(\"imdb\")\ntokenized_datasets = dataset.map(encode, batched=True, remove_columns=\"text\")\n\ninput_ids_t, input_ids_v, attention_mask_t, attention_mask_v, label_t, label_v = train_test_split(torch.tensor(tokenized_datasets['train']['input_ids']), torch.tensor(tokenized_datasets['train']['attention_mask']), torch.tensor(tokenized_datasets['train']['label']), \n                 random_state=SPLIT_RANDOM_SEED, test_size=TEST_SIZE, shuffle=True)\n\ntrain_dataset = TensorDataset(input_ids_t, attention_mask_t, label_t)\nval_dataset = TensorDataset(input_ids_v, attention_mask_v, label_v)\ntest_dataset = TensorDataset(torch.tensor(tokenized_datasets['test']['input_ids']), torch.tensor(tokenized_datasets['test']['attention_mask']), torch.tensor(tokenized_datasets['test']['label']))\n\nbatch_size = 16\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T17:33:40.404544Z","iopub.execute_input":"2024-02-16T17:33:40.404820Z","iopub.status.idle":"2024-02-16T17:36:25.470661Z","shell.execute_reply.started":"2024-02-16T17:33:40.404794Z","shell.execute_reply":"2024-02-16T17:36:25.469803Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"451e7adac83f46dfb54d848da48d6dfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c68e117ca4844be8b5f660542ba5c194"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04a9569c139e464cbbbc6c6496dee637"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41e370280c7c4da6937d1b26340f4809"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30dfe35302f1446ca9c7b82f6895d95d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3824d0a9406c4c12b70bdedab0ef937b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4de21b83992a448b9c21fa4000aa11da"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2024-02-07T14:30:05.652060Z","iopub.execute_input":"2024-02-07T14:30:05.652472Z","iopub.status.idle":"2024-02-07T14:30:05.660255Z","shell.execute_reply.started":"2024-02-07T14:30:05.652441Z","shell.execute_reply":"2024-02-07T14:30:05.659289Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 25000\n    })\n    unsupervised: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 50000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"wandb.login(key=\"eba16103be2afd0b5c96243771d60f5d7e562f68\")","metadata":{"execution":{"iopub.status.busy":"2024-02-16T17:36:25.471761Z","iopub.execute_input":"2024-02-16T17:36:25.472031Z","iopub.status.idle":"2024-02-16T17:36:27.385324Z","shell.execute_reply.started":"2024-02-16T17:36:25.472007Z","shell.execute_reply":"2024-02-16T17:36:27.384476Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# model = model.to(device)\nval_loss, val_acc = test(model, val_loader, device, tqdm_desc='Test')\nprint(f'Без обучения на датасете (чисто модель с параметрами) loss = {np.mean(val_loss)}, accuracy = {np.mean(val_acc)}')","metadata":{"execution":{"iopub.status.busy":"2024-02-08T11:16:01.663487Z","iopub.execute_input":"2024-02-08T11:16:01.664218Z","iopub.status.idle":"2024-02-08T11:31:45.287849Z","shell.execute_reply.started":"2024-02-08T11:16:01.664183Z","shell.execute_reply":"2024-02-08T11:31:45.286797Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Test: 100%|██████████| 1563/1563 [15:43<00:00,  1.66it/s]","output_type":"stream"},{"name":"stdout","text":"Без обучения на датасете (чисто модель с параметрами) loss = 0.1985105358434201, accuracy = 0.9360204734484965\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# model = model.to(device)\noptimizer = optim.Adam(model.parameters(), lr=2e-5, weight_decay=0.01)\ntrain_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer, 3, train_loader, val_loader, batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T14:11:41.294072Z","iopub.execute_input":"2024-02-08T14:11:41.295091Z","iopub.status.idle":"2024-02-08T17:22:51.092928Z","shell.execute_reply.started":"2024-02-08T14:11:41.295056Z","shell.execute_reply":"2024-02-08T17:22:51.092022Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:1j434940) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">grateful-surf-16</strong> at: <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/1j434940' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/1j434940</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240208_130549-1j434940/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:1j434940). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240208_141141-hkbzi7x5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/hkbzi7x5' target=\"_blank\">wandering-frog-17</a></strong> to <a href='https://wandb.ai/rodion-chernomordin/html%20classificator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rodion-chernomordin/html%20classificator' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/hkbzi7x5' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/hkbzi7x5</a>"},"metadata":{}},{"name":"stderr","text":"Training 0/3: 100%|██████████| 1563/1563 [44:08<00:00,  1.69s/it]\nValidating 0/3: 100%|██████████| 1563/1563 [19:23<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1\n train loss: 0.16785732328043257, train acc: 0.9389795265515035\n val loss: 0.1752058006864773, val acc: 0.9335812539987204\n\n","output_type":"stream"},{"name":"stderr","text":"Training 1/3: 100%|██████████| 1563/1563 [44:05<00:00,  1.69s/it]\nValidating 1/3: 100%|██████████| 1563/1563 [19:23<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2\n train loss: 0.13657005596608018, train acc: 0.9504958413307741\n val loss: 0.21571108164794275, val acc: 0.9181062060140754\n\n","output_type":"stream"},{"name":"stderr","text":"Training 2/3: 100%|██████████| 1563/1563 [44:05<00:00,  1.69s/it]\nValidating 2/3: 100%|██████████| 1563/1563 [19:22<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3\n train loss: 0.11670218710862076, train acc: 0.9582933461292387\n val loss: 0.2059667423575752, val acc: 0.9221049264235445\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.110 MB of 0.129 MB uploaded\\r'), FloatProgress(value=0.8477836324109216, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wandering-frog-17</strong> at: <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/hkbzi7x5' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/hkbzi7x5</a><br/>Synced 6 W&B file(s), 6 media file(s), 6 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240208_141141-hkbzi7x5/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T14:11:30.355420Z","iopub.execute_input":"2024-02-08T14:11:30.355758Z","iopub.status.idle":"2024-02-08T14:11:30.672543Z","shell.execute_reply.started":"2024-02-08T14:11:30.355732Z","shell.execute_reply":"2024-02-08T14:11:30.671462Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=2e-5, weight_decay=0.01)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=3, eta_min=3e-10)\ntrain_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer, 3, train_loader, val_loader, batch_size, scheduler)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T11:25:15.215421Z","iopub.execute_input":"2024-02-16T11:25:15.216021Z","iopub.status.idle":"2024-02-16T13:26:12.365581Z","shell.execute_reply.started":"2024-02-16T11:25:15.215992Z","shell.execute_reply":"2024-02-16T13:26:12.364691Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrodion-chernomordin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240216_112515-zx18zsb6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/zx18zsb6' target=\"_blank\">dazzling-moon-21</a></strong> to <a href='https://wandb.ai/rodion-chernomordin/html%20classificator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rodion-chernomordin/html%20classificator' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/zx18zsb6' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/zx18zsb6</a>"},"metadata":{}},{"name":"stderr","text":"Training 0/3: 100%|██████████| 1094/1094 [33:14<00:00,  1.82s/it]\nValidating 0/3: 100%|██████████| 469/469 [06:31<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1\n train loss: 0.2707482235032854, train acc: 0.8960237659963437\n val loss: 0.19148331692716333, val acc: 0.9282160625444207\n\n","output_type":"stream"},{"name":"stderr","text":"Training 1/3: 100%|██████████| 1094/1094 [33:25<00:00,  1.83s/it]\nValidating 1/3: 100%|██████████| 469/469 [06:37<00:00,  1.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2\n train loss: 0.16012315701955496, train acc: 0.941213436928702\n val loss: 0.19165448398827745, val acc: 0.9332356076759062\n\n","output_type":"stream"},{"name":"stderr","text":"Training 2/3: 100%|██████████| 1094/1094 [33:44<00:00,  1.85s/it]\nValidating 2/3: 100%|██████████| 469/469 [06:45<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3\n train loss: 0.0835013422281592, train acc: 0.9733775137111518\n val loss: 0.18641885535032954, val acc: 0.9361229566453447\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.064 MB of 0.092 MB uploaded\\r'), FloatProgress(value=0.697039459977499, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dazzling-moon-21</strong> at: <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/zx18zsb6' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/zx18zsb6</a><br/>Synced 6 W&B file(s), 6 media file(s), 6 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240216_112515-zx18zsb6/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"test_loss, test_acc = test(model, test_loader, device, tqdm_desc='Test')\nprint(f'loss = {np.mean(test_loss)}, accuracy = {np.mean(test_acc)}')","metadata":{"execution":{"iopub.status.busy":"2024-02-16T13:26:12.367883Z","iopub.execute_input":"2024-02-16T13:26:12.368595Z","iopub.status.idle":"2024-02-16T13:42:01.071017Z","shell.execute_reply.started":"2024-02-16T13:26:12.368554Z","shell.execute_reply":"2024-02-16T13:42:01.069865Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Test: 100%|██████████| 1563/1563 [15:48<00:00,  1.65it/s]","output_type":"stream"},{"name":"stdout","text":"loss = 0.17388345693760646, accuracy = 0.9378998720409469\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=2e-5, weight_decay=0.01)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=3e-10)\ntrain_loss_log, train_acc_log, val_loss_log, val_acc_log = train(model, optimizer, 5, train_loader, val_loader, batch_size, scheduler)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T17:36:27.387436Z","iopub.execute_input":"2024-02-16T17:36:27.388066Z","iopub.status.idle":"2024-02-16T20:52:17.553027Z","shell.execute_reply.started":"2024-02-16T17:36:27.388038Z","shell.execute_reply":"2024-02-16T20:52:17.552270Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrodion-chernomordin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240216_173627-488xlbnz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/488xlbnz' target=\"_blank\">luminous-bao-23</a></strong> to <a href='https://wandb.ai/rodion-chernomordin/html%20classificator' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/rodion-chernomordin/html%20classificator' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/488xlbnz' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/488xlbnz</a>"},"metadata":{}},{"name":"stderr","text":"Training 0/5: 100%|██████████| 1094/1094 [32:46<00:00,  1.80s/it]\nValidating 0/5: 100%|██████████| 469/469 [06:18<00:00,  1.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1\n train loss: 0.24377623107028917, train acc: 0.9031649908592322\n val loss: 0.23198189499027438, val acc: 0.9111140724946695\n\n","output_type":"stream"},{"name":"stderr","text":"Training 1/5: 100%|██████████| 1094/1094 [32:49<00:00,  1.80s/it]\nValidating 1/5: 100%|██████████| 469/469 [06:15<00:00,  1.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2\n train loss: 0.15352085591302383, train acc: 0.9429273308957953\n val loss: 0.19266452457207733, val acc: 0.9263059701492538\n\n","output_type":"stream"},{"name":"stderr","text":"Training 2/5: 100%|██████████| 1094/1094 [32:45<00:00,  1.80s/it]\nValidating 2/5: 100%|██████████| 469/469 [06:15<00:00,  1.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3\n train loss: 0.10570448501566783, train acc: 0.963989183424741\n val loss: 0.19919305919572267, val acc: 0.9287046908315565\n\n","output_type":"stream"},{"name":"stderr","text":"Training 3/5: 100%|██████████| 1094/1094 [32:46<00:00,  1.80s/it]\nValidating 3/5: 100%|██████████| 469/469 [06:15<00:00,  1.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4\n train loss: 0.04956031080909581, train acc: 0.9848606032906764\n val loss: 0.21317417312042117, val acc: 0.93363539445629\n\n","output_type":"stream"},{"name":"stderr","text":"Training 4/5: 100%|██████████| 1094/1094 [32:44<00:00,  1.80s/it]\nValidating 4/5: 100%|██████████| 469/469 [06:15<00:00,  1.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5\n train loss: 0.020495343316119536, train acc: 0.9954296160877514\n val loss: 0.2581087981553268, val acc: 0.933590973702914\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.226 MB of 0.226 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">luminous-bao-23</strong> at: <a href='https://wandb.ai/rodion-chernomordin/html%20classificator/runs/488xlbnz' target=\"_blank\">https://wandb.ai/rodion-chernomordin/html%20classificator/runs/488xlbnz</a><br/>Synced 6 W&B file(s), 10 media file(s), 10 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240216_173627-488xlbnz/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"test_loss, test_acc = test(model, test_loader, device, tqdm_desc='Test')\nprint(f'loss = {np.mean(test_loss)}, accuracy = {np.mean(test_acc)}')","metadata":{"execution":{"iopub.status.busy":"2024-02-16T20:52:17.554570Z","iopub.execute_input":"2024-02-16T20:52:17.554886Z","iopub.status.idle":"2024-02-16T21:07:55.490570Z","shell.execute_reply.started":"2024-02-16T20:52:17.554843Z","shell.execute_reply":"2024-02-16T21:07:55.489683Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Test: 100%|██████████| 1563/1563 [15:37<00:00,  1.67it/s]","output_type":"stream"},{"name":"stdout","text":"loss = 0.24936352291772165, accuracy = 0.9337811900191939\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}